{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dda0b0efc8ba86e81ec4</td>\n",
       "      <td>What are interesting facts about Microsoft his...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc708b74a108d0fc0ad9</td>\n",
       "      <td>What are those things which are not gonna happ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06a27ec5d82dacd8bfe0</td>\n",
       "      <td>What should I know to avoid being \"upsold\" whe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00cbb6b17e3ceb7c5358</td>\n",
       "      <td>How I add any account with payment bank?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c304888973a701585a0</td>\n",
       "      <td>Which Multi level marketing products are actua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>4bd96088d0b5f0f2c4f4</td>\n",
       "      <td>How is CSE at VIT Chennai?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>e80edbfc086f7125940f</td>\n",
       "      <td>How can we prevent a holocaust by robots, AI, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1506dfad6bd340782a1f</td>\n",
       "      <td>How can I help a student remember key steps an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>b56c60fd407f2f85553c</td>\n",
       "      <td>What is the difference between lace closure &amp; ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>a1b32d315c2782cdbcc3</td>\n",
       "      <td>What happens when you look into a broken mirror?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       dda0b0efc8ba86e81ec4   \n",
       "1       dc708b74a108d0fc0ad9   \n",
       "2       06a27ec5d82dacd8bfe0   \n",
       "3       00cbb6b17e3ceb7c5358   \n",
       "4       7c304888973a701585a0   \n",
       "...                      ...   \n",
       "999995  4bd96088d0b5f0f2c4f4   \n",
       "999996  e80edbfc086f7125940f   \n",
       "999997  1506dfad6bd340782a1f   \n",
       "999998  b56c60fd407f2f85553c   \n",
       "999999  a1b32d315c2782cdbcc3   \n",
       "\n",
       "                                            question_text  target  \n",
       "0       What are interesting facts about Microsoft his...       0  \n",
       "1       What are those things which are not gonna happ...       0  \n",
       "2       What should I know to avoid being \"upsold\" whe...       0  \n",
       "3                How I add any account with payment bank?       0  \n",
       "4       Which Multi level marketing products are actua...       0  \n",
       "...                                                   ...     ...  \n",
       "999995                         How is CSE at VIT Chennai?       0  \n",
       "999996  How can we prevent a holocaust by robots, AI, ...       0  \n",
       "999997  How can I help a student remember key steps an...       0  \n",
       "999998  What is the difference between lace closure & ...       0  \n",
       "999999   What happens when you look into a broken mirror?       0  \n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../datasets/train_df.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regexp Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['life',\n",
       " 'is',\n",
       " 'beautiful',\n",
       " 'so',\n",
       " 'enjoy',\n",
       " 'everymoment',\n",
       " 'you',\n",
       " 'have',\n",
       " 'runners',\n",
       " 'run',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'win']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "def regex_word_tokenizer(sent):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    sample_word_tokens = tokenizer.tokenize(sent)\n",
    "    sample_word_tokens = [word.lower() for word in sample_word_tokens]\n",
    "    return sample_word_tokens\n",
    "\n",
    "words = regex_word_tokenizer(str(\"Life is beautiful so Enjoy everymoment you have. Runners run hard to win\"))\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['life', 'beautiful', 'enjoy', 'everymoment', 'runners', 'run', 'hard', 'win']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_words_removal(words):\n",
    "    stop_words = [word.lower() for word in stopwords.words('english')]\n",
    "    word_tokens = [word for word in words if word.lower() not in stop_words]\n",
    "    return word_tokens\n",
    "\n",
    "stop_words_removal(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['life', 'beautiful', 'enjoy', 'everymoment', 'runner', 'run', 'hard', 'win']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def Lemmatizer(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return lemmatized_words\n",
    "\n",
    "Lemmatizer(stop_words_removal(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'life havv prpblems beautiful so enjoy every moment you have runners run hard to win caring careful careless '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_sentence(sent):\n",
    "    \n",
    "    # sentence = spellchecker(sent)\n",
    "    # tokens = word_tokenize(str(sent))\n",
    "    tokens = regex_word_tokenizer(str(sent))\n",
    "    # tokens = stop_words_removal(tokens)\n",
    "    # tokens = Lemmatizer(tokens)\n",
    "\n",
    "    sentence = \"\"\n",
    "    for word in tokens:\n",
    "        sentence += word + \" \"\n",
    "    return sentence\n",
    "\n",
    "format_sentence(\"Life havv prpblems beautiful so Enjoy every moment you have. Runners run hard to win caring careful careless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what are interesting facts about microsoft his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are those things which are not gonna happ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what should i know to avoid being upsold when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how i add any account with payment bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which multi level marketing products are actua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>how is cse at vit chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>how can we prevent a holocaust by robots ai or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>how can i help a student remember key steps an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>what is the difference between lace closure la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>what happens when you look into a broken mirror</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0       what are interesting facts about microsoft his...\n",
       "1       what are those things which are not gonna happ...\n",
       "2       what should i know to avoid being upsold when ...\n",
       "3                how i add any account with payment bank \n",
       "4       which multi level marketing products are actua...\n",
       "...                                                   ...\n",
       "999995                         how is cse at vit chennai \n",
       "999996  how can we prevent a holocaust by robots ai or...\n",
       "999997  how can i help a student remember key steps an...\n",
       "999998  what is the difference between lace closure la...\n",
       "999999   what happens when you look into a broken mirror \n",
       "\n",
       "[1000000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "\n",
    "for index,row in df.iterrows(): \n",
    "    if(row['target']==1):\n",
    "        X.append(format_sentence(row['question_text']))\n",
    "        Y.append(1)\n",
    "    else:\n",
    "        X.append(format_sentence(row['question_text']))\n",
    "        Y.append(0)\n",
    "\n",
    "X = pd.DataFrame(X,columns=[\"text\"])\n",
    "Y = pd.DataFrame(Y)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560940    are india russia china and iran slowly forming...\n",
      "215724                              why is my tit swelling \n",
      "646171    do i need to select an area of specialization ...\n",
      "800227    what is the full form of wgy in vehicle plate ...\n",
      "9327      is there any difference in it and cse at jss n...\n",
      "                                ...                        \n",
      "259178           what is a substitute for egg white powder \n",
      "365838    why do guys want to be a girl i don t i m happ...\n",
      "131932    why is us treasury department charging me 849 ...\n",
      "671155    what would happen if u s taxes were reduced to...\n",
      "121958    has anyone removed their removeable brace whil...\n",
      "Name: text, Length: 990000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X[\"text\"],Y,test_size=0.01,random_state = 42)\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# import numpy as np\n",
    "# rus = RandomUnderSampler(random_state=42,sampling_strategy=0.20)\n",
    "# X_data = X[\"text\"].values.reshape(-1,1)\n",
    "# X_train, y_train= rus.fit_resample(X_data,Y)\n",
    "\n",
    "# print(len(X_train),len(y_train))\n",
    "\n",
    "# ones = 0\n",
    "# zeros = 0\n",
    "# y_train = np.array(y_train)\n",
    "# for i in range(0,len(y_train)):\n",
    "#     if not y_train[i]:\n",
    "#         zeros+=1\n",
    "#     else:\n",
    "#         ones+=1\n",
    "# print(ones,zeros)\n",
    "\n",
    "# X_train,X_test,Y_train,Y_test = train_test_split(X_train,y_train,random_state = 42)\n",
    "# X_train = X_train.flatten()\n",
    "# X_test = X_test.flatten()\n",
    "# Y_train = Y_train.flatten()\n",
    "# Y_test = Y_test.flatten()\n",
    "# print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer().fit(X_train)\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vect = CountVectorizer().fit(X_train)\n",
    "\n",
    "##TFIDF\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "# tfidf_vectorizer=TfidfVectorizer(use_idf=True) \n",
    "# vect=tfidf_vectorizer.fit_transform(X_train) \n",
    "# vect=tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "# vect.get_feature_names()[::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<990000x168000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11444072 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorised = vect.transform(X_train)\n",
    "X_train_vectorised\n",
    "# print(len(Y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(penalty = \"l2\",C=0.30,max_iter = 2000,random_state = 42,solver=\"lbfgs\",class_weight={0:1,1:1.09},dual=False,intercept_scaling=1000)\n",
    "clf.fit(X_train_vectorised,np.array(Y_train[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([])\n",
    "probas = clf.predict_proba(vect.transform(X_test))\n",
    "y_pred = []\n",
    "for i in range(len(probas)):\n",
    "  if(probas[i][0]<0.80):\n",
    "    y_pred.append(1)\n",
    "  else:\n",
    "    y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(np.array(Y_test[0]), y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../datasets/test_df.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([])\n",
    "probas = clf.predict_proba(vect.transform(test_df[\"question_text\"]))\n",
    "y_pred = []\n",
    "for i in range(len(probas)):\n",
    "  if(probas[i][0]<0.80):\n",
    "    y_pred.append(1)\n",
    "  else:\n",
    "    y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop([\"question_text\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"target\"]=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('../results/lr_withProb0.80_classWeight110C030.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd69f43f58546b570e94fd7eba7b65e6bcc7a5bbc4eab0408017d18902915d69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
